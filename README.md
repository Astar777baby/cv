# A-Transformer/Astar777baby | Independent AI Researcher
Name: Liang Cheng
🌍 **Independent Deep Learning & Computer Vision Researcher**
Focusing on large-scale model optimization, Transformer architectures, and multimodal understanding.

---

## 🧠 Research Interests
- Deep Learning & Transformer Architectures
- Computer Vision & Multimodal Models
- Large Language Models (LLMs)
- 3D Vision, Face Analysis & Anti-Spoofing
- GPU Kernel Optimization (CUTLASS, FlashAttention, TensorRT)
- Efficient Inference & Model Quantization

---

## 🧩 Selected Projects
### 🔹 [SegMamba]
Exploring Mamba-based vision architectures for semantic segmentation and sequence modeling efficiency.

### 🔹 [DeepSeek-VL Integration]
Custom fine-tuning and inference optimization for Vision-Language models (OCR + structured extraction).

### 🔹 [OCR Microservices Pipeline]
End-to-end OCR system integrating PaddleOCR, YOLOv11, Triton Inference Server, and Kafka-based orchestration.

### 🔹 [Face Anti-Spoofing & Liveness Detection]
Developing robust face-based verification models using InsightFace, EfficientNet, and 3DMM-based reconstruction.

---

## 🧪 Technical Expertise
- **Frameworks:** PyTorch, TensorRT, DeepSpeed, Megatron-LM
- **Languages:** Python, C++, CUDA
- **Optimization:** FlashAttention, Quantization, Operator Fusion
- **Deployment:** Triton Inference Server, Docker, Kubernetes

---

## 🏆 Publications & Goals
Preparing independent research submissions for:

Focus areas:
> Efficient Transformer optimization, 3D vision, and liveness-based AI trust systems.

---

## 📫 Contact
- GitHub: [Astar777baby](https://github.com/Astar777baby)
- Email: `your.email@example.com`
- Location: Independent Researcher, Global

---

🧭 *This repository serves as a concise academic & technical CV for conference registration and collaboration.*
