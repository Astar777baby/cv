# A-Transformer/Astar777baby | Independent AI Researcher
Name: Liang Cheng
ðŸŒ **Independent Deep Learning & Computer Vision Researcher**
Focusing on large-scale model optimization, Transformer architectures, and multimodal understanding.

---

## ðŸ§  Research Interests
- Deep Learning & Transformer Architectures
- Computer Vision & Multimodal Models
- Large Language Models (LLMs)
- 3D Vision, Face Analysis & Anti-Spoofing
- GPU Kernel Optimization (CUTLASS, FlashAttention, TensorRT)
- Efficient Inference & Model Quantization

---

## ðŸ§© Selected Projects
### ðŸ”¹ [SegMamba]
Exploring Mamba-based vision architectures for semantic segmentation and sequence modeling efficiency.

### ðŸ”¹ [DeepSeek-VL Integration]
Custom fine-tuning and inference optimization for Vision-Language models (OCR + structured extraction).

### ðŸ”¹ [OCR Microservices Pipeline]
End-to-end OCR system integrating PaddleOCR, YOLOv11, Triton Inference Server, and Kafka-based orchestration.

### ðŸ”¹ [Face Anti-Spoofing & Liveness Detection]
Developing robust face-based verification models using InsightFace, EfficientNet, and 3DMM-based reconstruction.

---

## ðŸ§ª Technical Expertise
- **Frameworks:** PyTorch, TensorRT, DeepSpeed, Megatron-LM
- **Languages:** Python, C++, CUDA
- **Optimization:** FlashAttention, Quantization, Operator Fusion
- **Deployment:** Triton Inference Server, Docker, Kubernetes

---

## ðŸ† Publications & Goals
Preparing independent research submissions for:

Focus areas:
> Efficient Transformer optimization, 3D vision, and liveness-based AI trust systems.

---

## ðŸ“« Contact
- GitHub: [Astar777baby](https://github.com/Astar777baby)
- Email: `your.email@example.com`
- Location: Independent Researcher, Global

---

ðŸ§­ *This repository serves as a concise academic & technical CV for conference registration and collaboration.*
